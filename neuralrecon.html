<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="Alexiy's Blog Page" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <link href='https://fonts.googleapis.com/css?family=Roboto:400,400italic,700italic,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Condensed:300,300italic,700,700italic' rel='stylesheet' type='text/css'>
    <title>Paper Analysis: NeuralRecon</title>
  </head>

  <body>
    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
        </header>
    </div>

    <!-- CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

        <!-- TITLE -->
        <img alt="a Wild Me appears!" class="myimage" src="./images/me.jpeg"/>
        <p id="name">Alexiy Zhandarov</p>
        <p id="undername">Informatics B.Sc Student</p>

        <a id="home_link" href="index.html"><u>Home</u></a>
        <hr id=startmargin>

        <!-- ACTUAL START -->
        <h1 style="text-align:center">Paper Analysis on Real-Time 3D Scene Reconstruction from Monocular Video</h1>
        <p class="time"> May 20, 2022 </p>

        <!-- QUICK INTRO -->
        <p> In this blog post, I will review and analyze the paper NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video published in CVPR 2021 [1]
        After a brief introduction and going over the relevant terms, I will attempt to explain the algorithm and framework as simply as possible, observe an example, and finally dissect the results and see what it all means for the future of computer vision. </p>

        <video width="100%" height="250" autoplay muted>
          <source src="./images/web-scene2.m4v" type="video/mp4">
              Your browser does not support the video format.
              Try Using Chrome on PC.
          </video>
          <p class="explain"> Showcase of the proposed framework.[2] </p>


        <!-- INTRODUCTION -->
        <h3>Introduction</h3>
        <p>
          Scene reconstruction is one of the central tasks in 3D computer vision with currently numerous applications. 3D reconstruction has seen a wide range of usage within the medical industry, computer animation and graphics, virual reality(VR) and augmented reality(AR).
        </p>
        <p>
          Focusing in on the latter for example, to enable realistic and immersive interactions between the desired effects and the surrounding physical environment, the 3D reconstruction has many standards to fulfil; it needs to be accurate, coherent and performed without any noticeable delay.
        </p>
        <p>
          While camera motion can be tracked accurately with state-of-the-art visual-inertial SLAM systems [3], real-time image-based dense reconstruction remains to be a challenging problem due to <b>low reconstruction quality and high computation demands.</b> Slow and low quality algorithms are naturaly undesirable and can be unreliable when requiring precise results. The proposed framework 'NeuralRecon' attempts to address these issues. Moreover the method proposes a way avoiding the common path of depth-based methods, which uses TSDF fusion and per frame analyzation, and rather predicts it in a local window.
        </p>
        <img alt="result1" class="results" src="./images/results1.jpg"/>
        <p class="explain">
          Figure 1. Comparison between depth-based methods and the proposed 3D reconstruction method.
        </p>

        <!-- CONCEPTS -->
        <h3>Depth maps and computations</h3>
        <p>
          Depth maps are a vital instrument in attempting to recreate a model from images. They are clearly useful in a wide range of fields, however tend to set back the process' speed by their high number of computations. Most image-based real-time pipelines adopt the depth map fusion approach[4].
        </p>
        <p>
          Single-view depth maps are first estimated from each key frame and filtered for consistency and temporal smoothness, and lastely fused into a Truncated Signed Distance Function Volume (TSDF-V). <br>
          The reconstructed mesh can be then extracted from the fusion with the marching Cubes Algoorithm [5]. An Algorithm, originally intended for usage in medical imaging, using a divide-and-conquer approach to generate inter-slice connectivity, defining a triangle topology it processes 3D data in-order and calculates verticies using linear interpolation. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data.
        </p>
        <p>
          This approach suffers as the maps are estimated individually on each key frame. Additionaly each map is estimated in full leading to substantial overlap in the results.
          Estimating the same surfaces multiple times causes unnecessary computations, and may cause difficulties delivering correct results in certain areas.(see Figure 1)
        <!-- GRU -->
        <h3>Convolution reconstruction</h3>
        ...


        <h3>GRU</h3>
        ...


        <!-- Algorithm -->
        <h3>The algorithm</h3>
        ...

        <!-- Experiments -->
        <h3>The Experiments</h3>
        ...

        <!-- Experiments -->
        <h3>Results & Discussion</h3>
        ...

        <!-- References -->
        <div id="References">
        <h5><a href="#">References</a></h5>
        <ol>
            <li><a href="https://arxiv.org/pdf/2104.00681.pdf">Jiaming Sun, Yiming Xie1,Linghao Chen, Xiaowei Zhou, Hujun Bao, Zhejiang University, SenseTime Research - NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video</a></li>
            <li><a href="https://zju3dv.github.io/neuralrecon/">NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video Presentation Page</a></li>
            <li><a href="https://arxiv.org/pdf/2007.11898.pdf">Carlos Campos, Richard Elvira, Juan J. G´omez Rodr´ıguez, Jos´e M. M. Montiel, and Juan D. Tard´os. ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM. ArXiv, 2020.</a></li>
            <li><a href="https://www.researchgate.net/publication/284139276_3D_Modeling_on_the_Go_Interactive_3D_Reconstruction_of_Large-Scale_Scenes_on_Mobile_Devices">Thomas Schops, Torsten Sattler, Christian Hane, and Marc
              Pollefeys. 3D Modeling on the Go: Interactive 3D Reconstruction
              of Large-Scale Scenes on Mobile Devices. In 3DV,
              2015.</a></li>
              <li><a href="https://dl.acm.org/doi/pdf/10.1145/37402.37422">William E. Lorensen and Harvey E. Cline. Marching Cubes: A High Resolution 3D Surface Construction Algorithm. SIGGRAPH, 1987</a></li>

          </ol>
        </div>
      </section>


    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
        <footer class="inner">
          <p class="copyright">Theme heavily inspired by <a href="https://github.com/jasoncostello">Jason Costello</a></p>
          <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
        </footer>
      </div>

  </body>
</html>
